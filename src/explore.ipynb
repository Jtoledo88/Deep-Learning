{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Your code here\n",
                "# Import Packages\n",
                "import os\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from tensorflow import keras\n",
                "from keras.preprocessing import image\n",
                "import matplotlib.pyplot as mpimg"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import and Check first 9 Dog Pictures\n",
                "\n",
                "# Path to the directory containing your image data\n",
                "data_dir = \"../data/raw/train/\"\n",
                "\n",
                "\n",
                "# Get a list of all dog image file names and Get a list of all dog image file names\n",
                "dogs_imgs = [os.path.join(data_dir, img) for img in os.listdir(data_dir) if img.startswith(\"dog\")][:9]\n",
                "cats_imgs = [os.path.join(data_dir, img) for img in os.listdir(data_dir) if img.startswith(\"cat\")][:9]\n",
                "\n",
                "# Load the first nine dog images\n",
                "def show_images(images, title):\n",
                "    plt.figure(figsize=(10, 10))\n",
                "    for i in range(9):\n",
                "        plt.subplot(3, 3, i + 1)\n",
                "        img = mpimg.imread(images[i])\n",
                "        plt.imshow(img)\n",
                "        plt.axis('off')\n",
                "    plt.suptitle(title)\n",
                "    plt.show()\n",
                " \n",
                "show_images(dogs_imgs,'perritos')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def show_images(images, title):\n",
                "    plt.figure(figsize=(10, 10))\n",
                "    for i in range(9):\n",
                "        plt.subplot(3, 3, i + 1)\n",
                "        img = mpimg.imread(images[i])\n",
                "        plt.imshow(img)\n",
                "        plt.axis('off')\n",
                "    plt.suptitle(title)\n",
                "    plt.show()\n",
                " \n",
                "show_images(cats_imgs,'Gatitos')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "\n",
                "# Define a few rules for DataGen\n",
                "train_dir = \"../data/raw\"\n",
                "\n",
                "datagentrain = ImageDataGenerator()\n",
                "datagentest = ImageDataGenerator()\n",
                "\n",
                "# Generador de datos para las imágenes de train\n",
                "train_generator = datagentrain.flow_from_directory(\n",
                "    train_dir,\n",
                "    target_size = (200, 200),\n",
                "    classes = [\"dog\", \"cat\"]\n",
                ")\n",
                "\n",
                "# Generador de datos para las imágenes de test\n",
                "test_generator = datagentest.flow_from_directory(\n",
                "    directory=os.path.join(train_dir, \"test1\"),\n",
                "    target_size=(200, 200),\n",
                "    classes = ['test']\n",
                ")\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Move the Data Through the Neural Network\n",
                "from keras.models import Sequential\n",
                "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
                "\n",
                "model = Sequential()\n",
                "model.add(Conv2D(input_shape = (224,224,3), filters = 64, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 64,kernel_size = (3,3),padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "\n",
                "# Move the Data through the Dense Layers\n",
                "model.add(Flatten())\n",
                "model.add(Dense(units = 4096,activation = \"relu\"))\n",
                "model.add(Dense(units = 4096,activation = \"relu\"))\n",
                "model.add(Dense(units = 2, activation = \"softmax\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compile the Model using Adam \n",
                "from keras.optimizers import Adam\n",
                "\n",
                "# Compile the Model before Training\n",
                "model.compile(loss = keras.losses.categorical_crossentropy, optimizer = Adam(learning_rate = 0.001), metrics = [\"accuracy\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train the Model\n",
                "model.fit(train_generator, epochs = 1)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 64-bit ('3.8.13')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
